{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some fake data\n",
    "\n",
    "2 samples, 5 features each with 2 timesteps\n",
    "\n",
    "For example:\n",
    "\n",
    "|Sample | Feature | t_0 | t_1|\n",
    "| ----- | ----- | ----- | -----|\n",
    "| 1| X1 |  0.1 |  5.0 |\n",
    "|1 |   X2 | 0.2 | 0.8 |\n",
    "|1 | X3 |0.3 | 0.9 |\n",
    "| ... | ... | ... | ...|\n",
    "| 2 | X5 | 1.0 | 0.1|\n",
    "\n",
    "Labels:\n",
    "\n",
    "Binary predictions here so 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "[0.1, 5.0], \n",
    "[0.2, 0.8],\n",
    "[0.3, 0.9],\n",
    "[0.4, 0.8],\n",
    "[0.5, 0.6],\n",
    "[0.6, 0.5], \n",
    "[0.7, 0.4],\n",
    "[0.8, 0.4],\n",
    "[0.9, 0.1],\n",
    "[1.0, 0.1]])\n",
    "\n",
    "y = np.array([[0],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Data\n",
    "\n",
    "Format is (nsamples, nfeatures, ntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_FEATURES 5\n",
      "N_SAMPLES 2\n",
      "\n",
      "Original data shape: (10, 2)\n",
      "Shape after reshape: (2, 5, 2)\n",
      "New data shape:\n",
      "[[[0.1 5. ]\n",
      "  [0.2 0.8]\n",
      "  [0.3 0.9]\n",
      "  [0.4 0.8]\n",
      "  [0.5 0.6]]\n",
      "\n",
      " [[0.6 0.5]\n",
      "  [0.7 0.4]\n",
      "  [0.8 0.4]\n",
      "  [0.9 0.1]\n",
      "  [1.  0.1]]]\n",
      "\n",
      "Label shape: (2, 1)\n",
      "[[0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "n_time = 2\n",
    "n_features = 5\n",
    "n_samples = data.shape[0]/n_features\n",
    "\n",
    "print(\"N_FEATURES %d\" % n_features)\n",
    "print(\"N_SAMPLES %d\" % n_samples)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Original data shape: \" + str(data.shape))\n",
    "X_train = data.reshape(n_samples, n_features, n_time)\n",
    "print(\"Shape after reshape: \" + str(X_train.shape))\n",
    "print(\"New data shape:\")\n",
    "print(X_train)\n",
    "\n",
    "print(\"\")\n",
    "y_train = y.reshape(n_samples,1)\n",
    "print(\"Label shape: \" + str(y_train.shape))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add LSTM layers\n",
    "\n",
    "Obviously two layers is overkill for this example, but it demonstrates the slight differences in the layer definitions following the first LSTM.\n",
    "\n",
    "Note that in order to stack LSTM layers, you need to have return_sequences = True for the first n-1 layers and False for the last LSTM layer.\n",
    "\n",
    "For a single LSTM layer, return_sequences should be set to false if you are doing a binary prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 0.6741 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6723 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6706 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6687 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6669 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6651 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6632 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6613 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6593 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6574 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5046ebc150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(8, return_sequences=True,input_shape=(n_features, n_time)))\n",
    "model.add(LSTM(8, return_sequences=False))\n",
    "model.add(Dense(1, activation=('sigmoid')))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=10,\n",
    "          batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
